{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4720ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORT C√ÅC TH∆Ø VI·ªÜN C·∫¶N THI·∫æT CHO XAI-RL FRAMEWORK\n",
    "# ============================================================================\n",
    "\n",
    "# 1. System & Path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('d:\\\\NCKH\\\\SARSA_FinancialRL')\n",
    "\n",
    "# 2. Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# 3. Deep Learning - PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 4. Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style cho plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 5. XAI Libraries - CH·ªà D√ôNG SHAP\n",
    "try:\n",
    "    import shap\n",
    "    print(\"‚úì SHAP available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö† SHAP not installed - will install when needed\")\n",
    "\n",
    "# 6. Project-specific Imports\n",
    "from agents.d_sarsa.d_sarsa import Qsa\n",
    "from environments.stock_trading_env.mdp import StockTradingMDP\n",
    "from data.data_provider.library_extracted.vnstock.VNStockDataProvider import VNStockDataProvider\n",
    "from data.data_processor.feature_engineer import engineer_stat as es\n",
    "\n",
    "# 7. Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚úì T·∫•t c·∫£ th∆∞ vi·ªán ƒë√£ ƒë∆∞·ª£c import th√†nh c√¥ng!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüéØ XAI-RL Framework - 3 Ph∆∞∆°ng ph√°p ƒë·ªôc l·∫≠p:\")\n",
    "print(\"  [1] RDX  - Reward Decomposition (weights t·ª´ domain knowledge)\")\n",
    "print(\"  [2] MSX  - Multi-Step Explanation (trajectory analysis)\")\n",
    "print(\"  [3] SHAP - Feature Attribution (Shapley values)\")\n",
    "print(\"\\nüìä Deep RL Agent:\")\n",
    "print(\"  ‚Ä¢ Qsa:              Q-network (input=7, output=11)\")\n",
    "print(\"  ‚Ä¢ StockTradingMDP:  Environment cho stock trading\")\n",
    "print(\"  ‚Ä¢ VNStockData:      Data provider cho VN market\")\n",
    "print(\"\\nReady to analyze SARSA agent! üöÄ\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a746ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1. Load model SARSA\n",
    "qsa = Qsa(input_size=7, num_classes=11)\n",
    "model_path_1 = 'd:\\\\NCKH\\\\SARSA_FinancialRL\\\\models\\\\sarsa_good_acb.pth'\n",
    "\n",
    "if os.path.exists(model_path_1):\n",
    "    state_dict = torch.load(model_path_1, map_location=torch.device('cpu'))\n",
    "    qsa.load_state_dict(state_dict)\n",
    "    qsa.eval()\n",
    "    print(f\"‚úì Model loaded: {model_path_1}\")\n",
    "else:\n",
    "    print(f\"‚úó Model not found: {model_path_1}\")\n",
    "\n",
    "# # 1.2. Load d·ªØ li·ªáu \n",
    "# provider = VNStockDataProvider()\n",
    "# print(\"\\nƒêang l·∫•y d·ªØ li·ªáu t·ª´ vnstock...\")\n",
    "# df_raw = provider.get_ohlcv_data('SSI', '2021-12-14', '2024-12-31')\n",
    "# print(f\"‚úì ƒê√£ l·∫•y {len(df_raw)} d√≤ng d·ªØ li·ªáu\")\n",
    "\n",
    "# # 1.3. X·ª≠ l√Ω d·ªØ li·ªáu v√† th√™m technical indicators\n",
    "# df_processed = df_raw.copy()\n",
    "# df_processed.rename(columns={'date': 'time'}, inplace=True)\n",
    "# df_processed['time'] = pd.to_datetime(df_processed['time']).dt.strftime('%d/%m/%Y')\n",
    "# df_processed = es.add_technical_indicators(df_processed, start_date= '01/01/2022')\n",
    "# print(f\"‚úì ƒê√£ th√™m technical indicators: {df_processed.shape}\")\n",
    "\n",
    "df_processed_train = pd.read_csv('D:\\\\NCKH\\\\SARSA_FinancialRL\\\\data\\\\data_storer\\\\data_research\\\\train\\\\good_train_SSI.csv')\n",
    "df_processed_train.rename(columns={'date': 'time'}, inplace=True)\n",
    "df_processed_train['time'] = pd.to_datetime(df_processed_train['time']).dt.strftime('%d/%m/%Y')\n",
    "\n",
    "df_processed_test = pd.read_csv('D:\\\\NCKH\\\\SARSA_FinancialRL\\\\data\\\\data_storer\\\\data_research\\\\test\\\\good_test_SSI.csv')\n",
    "df_processed_test.rename(columns={'date': 'time'}, inplace=True)\n",
    "df_processed_test['time'] = pd.to_datetime(df_processed_test['time']).dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Gh√©p d·ªØ li·ªáu: train tr∆∞·ªõc r·ªìi ƒë·∫øn test (theo th·ªùi gian) thay v√¨ d√πng to√°n t·ª≠ '+'\n",
    "df_processed = pd.concat([df_processed_train, df_processed_test], ignore_index=True)\n",
    "# ƒê·∫£m b·∫£o th·ª© t·ª± th·ªùi gian tƒÉng d·∫ßn n·∫øu ch∆∞a ch·∫Øc ch·∫Øn\n",
    "_df_time = pd.to_datetime(df_processed['time'], format='%d/%m/%Y')\n",
    "df_processed = df_processed.assign(_time=_df_time).sort_values('_time').drop(columns=['_time']).reset_index(drop=True)\n",
    "print(f\"‚úì Merged train+test: {df_processed.shape} (train={df_processed_train.shape}, test={df_processed_test.shape})\")\n",
    "print(f\"  Time range: {df_processed['time'].iloc[0]} -> {df_processed['time'].iloc[-1]}\")\n",
    "\n",
    "# 1.4. Kh·ªüi t·∫°o MDP v√† ch·∫°y simulation\n",
    "mdp = StockTradingMDP(balance_init=1000, k=5, min_balance=-100)\n",
    "\n",
    "def pi_deep(s, eps=0.0, greedy=True):\n",
    "    with torch.no_grad():\n",
    "        out_qsa = qsa(torch.Tensor(s).float()).squeeze()\n",
    "        action = out_qsa.argmax().item() - 5\n",
    "    return action\n",
    "\n",
    "# State ban ƒë·∫ßu\n",
    "first_row = df_processed.iloc[0]\n",
    "state_init = [\n",
    "    float(first_row['close']),\n",
    "    mdp.balance_init,\n",
    "    0,\n",
    "    float(first_row['MACD']),\n",
    "    float(first_row['RSI']),\n",
    "    float(first_row['CCI']),\n",
    "    float(first_row['ADX'])\n",
    "]\n",
    "\n",
    "# Ch·∫°y simulation\n",
    "print(\"\\nƒêang ch·∫°y simulation...\")\n",
    "states, rewards, actions = mdp.simulate(\n",
    "    df_processed[1:].reset_index(drop=True), \n",
    "    state_init, \n",
    "    pi_deep, \n",
    "    greedy=True, \n",
    "    eps=0.0\n",
    ")\n",
    "\n",
    "print(f\"‚úì Simulation ho√†n t·∫•t: {len(states)} states, {len(actions)} actions\")\n",
    "print(f\"  Total reward: {sum(rewards):.2f}\")\n",
    "print(f\"  Final portfolio: ${states[-1][1] + states[-1][0]*states[-1][2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1.2. Load d·ªØ li·ªáu ACB\n",
    "# provider = VNStockDataProvider()\n",
    "# print(\"\\nƒêang l·∫•y d·ªØ li·ªáu ACB t·ª´ vnstock...\")\n",
    "# df_raw = provider.get_ohlcv_data('ACB', '2012-12-14', '2022-12-31')\n",
    "# print(f\"‚úì ƒê√£ l·∫•y {len(df_raw)} d√≤ng d·ªØ li·ªáu\")\n",
    "\n",
    "# # 1.3. X·ª≠ l√Ω d·ªØ li·ªáu v√† th√™m technical indicators\n",
    "# df_processed = df_raw.copy()\n",
    "# df_processed.rename(columns={'date': 'time'}, inplace=True)\n",
    "# df_processed['time'] = pd.to_datetime(df_processed['time']).dt.strftime('%d/%m/%Y')\n",
    "# df_processed = es.add_technical_indicators(df_processed, start_date= '01/01/2013')\n",
    "# print(f\"‚úì ƒê√£ th√™m technical indicators: {df_processed.shape}\")\n",
    "\n",
    "# # 1.4. Kh·ªüi t·∫°o MDP v√† ch·∫°y simulation\n",
    "# mdp = StockTradingMDP(balance_init=1000, k=5, min_balance=-100)\n",
    "\n",
    "# def pi_deep(s, eps=0.0, greedy=True):\n",
    "#     with torch.no_grad():\n",
    "#         out_qsa = qsa(torch.Tensor(s).float()).squeeze()\n",
    "#         action = out_qsa.argmax().item() - 5\n",
    "#     return action\n",
    "\n",
    "# # State ban ƒë·∫ßu\n",
    "# first_row = df_processed.iloc[0]\n",
    "# state_init = [\n",
    "#     float(first_row['close']),\n",
    "#     mdp.balance_init,\n",
    "#     0,\n",
    "#     float(first_row['MACD']),\n",
    "#     float(first_row['RSI']),\n",
    "#     float(first_row['CCI']),\n",
    "#     float(first_row['ADX'])\n",
    "# ]\n",
    "\n",
    "# # Ch·∫°y simulation\n",
    "# print(\"\\nƒêang ch·∫°y simulation...\")\n",
    "# states, rewards, actions = mdp.simulate(\n",
    "#     df_processed[1:].reset_index(drop=True), \n",
    "#     state_init, \n",
    "#     pi_deep, \n",
    "#     greedy=True, \n",
    "#     eps=0.0\n",
    "# )\n",
    "\n",
    "# print(f\"‚úì Simulation ho√†n t·∫•t: {len(states)} states, {len(actions)} actions\")\n",
    "# print(f\"  Total reward: {sum(rewards):.2f}\")\n",
    "# print(f\"  Final portfolio: ${states[-1][1] + states[-1][0]*states[-1][2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cd335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1.1. Load model SARSA\n",
    "# qsa = Qsa(input_size=7, num_classes=11)\n",
    "# model_path_1 = 'd:\\\\NCKH\\\\SARSA_FinancialRL\\\\models\\\\sarsa_bad_acb.pth'\n",
    "\n",
    "# if os.path.exists(model_path_1):\n",
    "#     state_dict = torch.load(model_path_1, map_location=torch.device('cpu'))\n",
    "#     qsa.load_state_dict(state_dict)\n",
    "#     qsa.eval()\n",
    "#     print(f\"‚úì Model loaded: {model_path_1}\")\n",
    "# else:\n",
    "#     print(f\"‚úó Model not found: {model_path_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d19462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_processed_1 = pd.read_csv('D:\\\\NCKH\\\\SARSA_FinancialRL\\\\data\\\\data_storer\\\\data_research\\\\test\\\\good_test_ACB.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1.4. Kh·ªüi t·∫°o MDP v√† ch·∫°y simulation\n",
    "# mdp = StockTradingMDP(balance_init=1000, k=5, min_balance=-100)\n",
    "\n",
    "# def pi_deep(s, eps=0.0, greedy=True):\n",
    "#     with torch.no_grad():\n",
    "#         out_qsa = qsa(torch.Tensor(s).float()).squeeze()\n",
    "#         action = out_qsa.argmax().item() - 5\n",
    "#     return action\n",
    "\n",
    "# # State ban ƒë·∫ßu\n",
    "# first_row = df_processed_1.iloc[0]\n",
    "# state_init = [\n",
    "#     float(first_row['close']),\n",
    "#     mdp.balance_init,\n",
    "#     0,\n",
    "#     float(first_row['MACD']),\n",
    "#     float(first_row['RSI']),\n",
    "#     float(first_row['CCI']),\n",
    "#     float(first_row['ADX'])\n",
    "# ]\n",
    "\n",
    "# # Ch·∫°y simulation\n",
    "# print(\"\\nƒêang ch·∫°y simulation...\")\n",
    "# states, rewards, actions = mdp.simulate(\n",
    "#     df_processed_1[1:].reset_index(drop=True), \n",
    "#     state_init, \n",
    "#     pi_deep, \n",
    "#     greedy=True, \n",
    "#     eps=0.0\n",
    "# )\n",
    "\n",
    "# print(f\"‚úì Simulation ho√†n t·∫•t: {len(states)} states, {len(actions)} actions\")\n",
    "# print(f\"  Total reward: {sum(rewards):.2f}\")\n",
    "# print(f\"  Final portfolio: ${states[-1][1] + states[-1][0]*states[-1][2]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d71df",
   "metadata": {},
   "source": [
    "## SHAP cho states agent v·ª´a m√¥ ph·ªèng\n",
    "M·ª•c ti√™u: gi·∫£i th√≠ch ƒë√≥ng g√≥p c·ªßa t·ª´ng feature (gi√°, v·ªën, v·ªã th·∫ø, MACD, RSI, CCI, ADX) l√™n Q-value c·ªßa h√†nh ƒë·ªông m√† agent ƒë√£ ch·ªçn t·∫°i m·ªói timestep. Ch√∫ng ta s·ª≠ d·ª•ng KernelExplainer cho d·ªØ li·ªáu tabular v√† h√†m d·ª± ƒëo√°n tr·∫£ v·ªÅ Q-value c·ªßa h√†nh ƒë·ªông ƒë√£ th·ª±c thi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141fb6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chu·∫©n b·ªã d·ªØ li·ªáu X v√† h√†m d·ª± ƒëo√°n cho SHAP\n",
    "import importlib\n",
    "if importlib.util.find_spec('shap') is None:\n",
    "    import sys, subprocess\n",
    "    print('ƒêang c√†i ƒë·∫∑t shap...')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'shap'])\n",
    "    import shap\n",
    "else:\n",
    "    import shap\n",
    "\n",
    "# Ma tr·∫≠n tr·∫°ng th√°i t·ª´ m√¥ ph·ªèng\n",
    "X = np.array(states, dtype=np.float32)\n",
    "feature_names = ['close','balance','position','MACD','RSI','CCI','ADX']\n",
    "\n",
    "# H√†m d·ª± ƒëo√°n: tr·∫£ v·ªÅ Q-value c·ªßa h√†nh ƒë·ªông greedy (argmax) cho m·ªói h√†ng\n",
    "def predict_q_greedy(X_batch):\n",
    "    X_t = torch.tensor(X_batch, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        q = qsa(X_t)  # [N, 11]\n",
    "        # L·∫•y Q-value theo h√†nh ƒë·ªông c√≥ Q l·ªõn nh·∫•t cho t·ª´ng h√†ng\n",
    "        ai = torch.argmax(q, dim=1)  # [N]\n",
    "        out = q.gather(dim=1, index=ai.view(-1,1)).squeeze(1)  # [N]\n",
    "        return out.cpu().numpy().astype(np.float32)\n",
    "\n",
    "print(f'X shape: {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√≠nh SHAP values v·ªõi KernelExplainer (c√≥ th·ªÉ m·∫•t v√†i ph√∫t v·ªõi d·ªØ li·ªáu l·ªõn)\n",
    "# Ch·ªçn background nh·ªè ƒë·ªÉ tƒÉng t·ªëc\n",
    "rng = np.random.default_rng(42)\n",
    "bg_idx = rng.choice(len(X), size=min(3000, len(X)), replace=False)\n",
    "X_bg = X[bg_idx]\n",
    "\n",
    "# Ch·ªçn sample ƒë·ªÉ gi·∫£i th√≠ch (v√≠ d·ª• 300 b∆∞·ªõc g·∫ßn nh·∫•t ho·∫∑c to√†n b·ªô n·∫øu √≠t h∆°n)\n",
    "sample_len = len(X)\n",
    "X_sample = X[-sample_len:]\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_q_greedy, X_bg)\n",
    "shap_values = explainer.shap_values(X_sample, nsamples='auto')\n",
    "print('‚úì ƒê√£ t√≠nh xong SHAP values cho sample:', len(X_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√≠nh ma tr·∫≠n t∆∞∆°ng quan v√† v·∫Ω heatmap\n",
    "# S·ª≠ d·ª•ng d·ªØ li·ªáu states ƒë√£ m√¥ ph·ªèng\n",
    "X = np.array(states, dtype=np.float32)\n",
    "feature_names = ['close','balance','position','MACD','RSI','CCI','ADX']\n",
    "\n",
    "# T·∫°o DataFrame ƒë·ªÉ t√≠nh t∆∞∆°ng quan\n",
    "X_df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c h√†ng c√≥ NaN (n·∫øu c√≤n)\n",
    "X_df_clean = X_df.dropna()\n",
    "\n",
    "# T√≠nh ma tr·∫≠n t∆∞∆°ng quan Pearson\n",
    "corr = X_df_clean.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1, square=True,\n",
    "            fmt='.2f', linewidths=0.5, cbar_kws={'shrink': 0.8})\n",
    "plt.title('Ma tr·∫≠n t∆∞∆°ng quan (Pearson) gi·ªØa c√°c thu·ªôc t√≠nh tr·∫°ng th√°i')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: summary bar + beeswarm cho sample\n",
    "plt.figure(figsize=(10,6))\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_names, plot_type='bar', show=False)\n",
    "# plt.title('SHAP Summary (Bar) - Q c·ªßa h√†nh ƒë·ªông ƒë√£ th·ª±c thi')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=False)\n",
    "# plt.title('SHAP Beeswarm - Ph√¢n ph·ªëi ƒë√≥ng g√≥p theo timestep')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall cho m·ªôt timestep c·ª• th·ªÉ (v√≠ d·ª• timestep cu·ªëi c√πng)\n",
    "idx = -1  # ph·∫ßn t·ª≠ cu·ªëi c·ªßa sample\n",
    "base_val = np.mean(predict_q_greedy(X_bg))\n",
    "shap.plots.waterfall(shap.Explanation(values=shap_values[idx],\n",
    "                                       base_values=base_val,\n",
    "                                       data=X_sample[idx],\n",
    "                                       feature_names=feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "def save_analysis_to_pdf(X_df_clean, shap_values, X_sample, feature_names, base_val, output_path):\n",
    "    \"\"\"\n",
    "    L∆∞u c√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch (Heatmap, SHAP Bar, SHAP Beeswarm, SHAP Waterfall) v√†o 1 file PDF.\n",
    "    \n",
    "    Args:\n",
    "        X_df_clean: DataFrame ƒë√£ l√†m s·∫°ch ƒë·ªÉ v·∫Ω Heatmap.\n",
    "        shap_values: Gi√° tr·ªã SHAP ƒë√£ t√≠nh to√°n.\n",
    "        X_sample: D·ªØ li·ªáu m·∫´u d√πng ƒë·ªÉ t√≠nh SHAP.\n",
    "        feature_names: Danh s√°ch t√™n c√°c ƒë·∫∑c tr∆∞ng.\n",
    "        base_val: Gi√° tr·ªã n·ªÅn (base value) cho Waterfall plot.\n",
    "        output_path: ƒê∆∞·ªùng d·∫´n l∆∞u file PDF (VD: 'reports/analysis_report.pdf').\n",
    "    \"\"\"\n",
    "    print(f\"ƒêang t·∫°o file PDF t·∫°i: {output_path}...\")\n",
    "    \n",
    "    # K√≠ch th∆∞·ªõc chu·∫©n A4 (ngang ho·∫∑c d·ªçc t√πy ch·ªânh, ·ªü ƒë√¢y d√πng Landscape cho d·ªÖ nh√¨n SHAP)\n",
    "    # A4 size in inches: 8.27 x 11.69. Landscape: 11.69 x 8.27\n",
    "    A4_WIDTH = 11.69\n",
    "    A4_HEIGHT = 8.27\n",
    "\n",
    "    with PdfPages(output_path) as pdf:\n",
    "        \n",
    "        # --- TRANG 1: MA TR·∫¨N T∆Ø∆†NG QUAN (HEATMAP) ---\n",
    "        fig1 = plt.figure(figsize=(10, 8)) # Canh ch·ªânh cho v·ª´a trang\n",
    "        corr = X_df_clean.corr(method='pearson')\n",
    "        sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1, square=True,\n",
    "                    fmt='.2f', linewidths=0.5, cbar_kws={'shrink': 0.8})\n",
    "        # plt.title('Ma tr·∫≠n t∆∞∆°ng quan (Pearson) gi·ªØa c√°c thu·ªôc t√≠nh tr·∫°ng th√°i', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig1)  # L∆∞u trang hi·ªán t·∫°i\n",
    "        plt.close(fig1)    # Gi·∫£i ph√≥ng b·ªô nh·ªõ\n",
    "\n",
    "        # --- TRANG 2: SHAP SUMMARY (BAR PLOT) ---\n",
    "        fig2 = plt.figure(figsize=(10, 6))\n",
    "        # show=False ƒë·ªÉ kh√¥ng hi·ªÉn th·ªã ngay m√† l∆∞u v√†o figure hi·ªán t·∫°i\n",
    "        shap.summary_plot(shap_values, X_sample, feature_names=feature_names, \n",
    "                          plot_type='bar', show=False)\n",
    "        plt.title('M·ª©c ƒë·ªô quan tr·ªçng c·ªßa ƒë·∫∑c tr∆∞ng (SHAP Bar)', fontsize=14)\n",
    "        # bbox_inches='tight' c·ª±c quan tr·ªçng v·ªõi SHAP ƒë·ªÉ kh√¥ng b·ªã c·∫Øt ch·ªØ\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig2, bbox_inches='tight') \n",
    "        plt.close(fig2)\n",
    "\n",
    "        # --- TRANG 3: SHAP SUMMARY (BEESWARM PLOT) ---\n",
    "        fig3 = plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=False)\n",
    "        # plt.title('Ph√¢n ph·ªëi t√°c ƒë·ªông c·ªßa ƒë·∫∑c tr∆∞ng (SHAP Beeswarm)', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig3, bbox_inches='tight')\n",
    "        plt.close(fig3)\n",
    "\n",
    "        # --- TRANG 4: SHAP WATERFALL (TIMESTEP CU·ªêI) ---\n",
    "        # Waterfall c·ªßa SHAP v·∫Ω h∆°i kh√°c, c·∫ßn x·ª≠ l√Ω kh√©o\n",
    "        fig4 = plt.figure(figsize=(10, 6))\n",
    "        idx = -1\n",
    "        \n",
    "        # Waterfall plot v·∫Ω tr·ª±c ti·∫øp l√™n current figure\n",
    "        shap.plots.waterfall(shap.Explanation(values=shap_values[idx],\n",
    "                                              base_values=base_val,\n",
    "                                              data=X_sample[idx],\n",
    "                                              feature_names=feature_names),\n",
    "                             show=False) # Quan tr·ªçng: show=False\n",
    "        \n",
    "        # Waterfall th∆∞·ªùng kh√¥ng c√≥ title m·∫∑c ƒë·ªãnh, ta c√≥ th·ªÉ add th√™m n·∫øu mu·ªën\n",
    "        # plt.title(f'Gi·∫£i th√≠ch chi ti·∫øt cho m·∫´u cu·ªëi c√πng (Index {idx})', fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig4, bbox_inches='tight')\n",
    "        plt.close(fig4)\n",
    "        \n",
    "    print(\"‚úì ƒê√£ l∆∞u th√†nh c√¥ng file PDF!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbc9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# --- 1. SETUP ƒê∆Ø·ªúNG D·∫™N OUTPUT ---\n",
    "output_dir = \"D:\\\\NCKH\\\\SARSA_FinancialRL\\\\application\\\\results\\\\xai_analysis\\\\\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- 2. PARSE T√äN THEO ƒê√öNG FORMAT Y√äU C·∫¶U ---\n",
    "# ƒê·ªãnh d·∫°ng: SHAP_Report_<agentStage>_SARSA_<dataStage>_<ticker>.pdf\n",
    "# - agentStage: l·∫•y t·ª´ t√™n file model (good/bad)\n",
    "# - dataStage: l·∫•y t·ª´ ngu·ªìn df_processed (good/bad)\n",
    "# - ticker: t√™n c·ªï phi·∫øu d√πng ƒë·ªÉ l·∫•y d·ªØ li·ªáu (t·ª´ ngu·ªìn df_processed)\n",
    "\n",
    "# 2.1 Parse agentStage t·ª´ model_path_1\n",
    "file_name_raw = os.path.splitext(os.path.basename(model_path_1))[0]\n",
    "parts = file_name_raw.split('_')\n",
    "# v√≠ d·ª•: 'sarsa_good_acb' -> ['sarsa','good','acb']\n",
    "agentStage = (parts[1] if len(parts) > 1 else 'unknown').upper()\n",
    "\n",
    "# 2.2 Parse dataStage & ticker t·ª´ c√°c ƒë∆∞·ªùng d·∫´n data ƒë√£ d√πng ƒë·ªÉ t·∫°o df_processed\n",
    "# ∆Øu ti√™n bi·∫øn df_processed_train / df_processed_test n·∫øu t·ªìn t·∫°i t√™n file\n",
    "_data_paths = []\n",
    "try:\n",
    "    _data_paths.append('D:\\\\NCKH\\\\SARSA_FinancialRL\\\\data\\\\data_storer\\\\data_research\\\\train\\\\good_train_SSI.csv')\n",
    "    _data_paths.append('D:\\\\NCKH\\\\SARSA_FinancialRL\\\\data\\\\data_storer\\\\data_research\\\\test\\\\good_test_SSI.csv')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Heuristic: t√¨m \"good\"/\"bad\" trong path ƒë·ªÉ x√°c ƒë·ªãnh dataStage\n",
    "dataStage = 'UNKNOWN'\n",
    "ticker = 'UNKNOWN'\n",
    "for p in _data_paths:\n",
    "    base = os.path.basename(p).lower()\n",
    "    if 'good' in base:\n",
    "        dataStage = 'GOOD'\n",
    "    elif 'bad' in base:\n",
    "        dataStage = 'BAD'\n",
    "    # c·ªë g·∫Øng b·∫Øt ticker b·∫±ng regex: *_<TICKER>.csv\n",
    "    m = re.search(r\"_([A-Za-z]{2,5})\\.csv$\", base)\n",
    "    if m:\n",
    "        ticker = m.group(1).upper()\n",
    "\n",
    "# N·∫øu v·∫´n UNKNOWN ticker, th·ª≠ suy t·ª´ df_processed columns (kh√¥ng b·∫Øt bu·ªôc)\n",
    "if ticker == 'UNKNOWN':\n",
    "    # n·∫øu c√≥ bi·∫øn df_processed v√† c√≥ c·ªôt 'symbol' th√¨ l·∫•y unique ƒë·∫ßu ti√™n\n",
    "    try:\n",
    "        if 'symbol' in df_processed.columns:\n",
    "            ticker = str(df_processed['symbol'].iloc[0]).upper()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# --- 3. T·∫†O T√äN FILE THEO ƒê√öNG QUY ∆Ø·ªöC ---\n",
    "pdf_filename = f\"SHAP_Report_{agentStage}_SARSA_{dataStage}_{ticker}.pdf\"\n",
    "full_output_path = os.path.join(output_dir, pdf_filename)\n",
    "\n",
    "print(f\"ü§ñ Nh·∫≠n di·ªán: agentStage={agentStage}, dataStage={dataStage}, ticker={ticker}\")\n",
    "print(f\"üìÑ S·∫Ω l∆∞u PDF: {pdf_filename}\")\n",
    "\n",
    "# --- 4. G·ªåI H√ÄM L∆ØU PDF ---\n",
    "try:\n",
    "    save_analysis_to_pdf(X_df_clean, shap_values, X_sample, feature_names, base_val, full_output_path)\n",
    "    print(f\"‚úì ƒê√£ l∆∞u xong t·∫°i: {full_output_path}\")\n",
    "except PermissionError:\n",
    "    print(\"‚ùå L·ªñI: File ƒëang m·ªü, vui l√≤ng ƒë√≥ng file PDF l·∫°i!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696cc68e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
